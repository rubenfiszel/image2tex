'''
Adapted from Keras cifar10 example:
https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py

'''

from __future__ import print_function
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.utils import np_utils

import pickle
import glob
import numpy as np
import cv2
import json




def read_example_images(example_path = "char2png/output/*.png", shape=(28,28)):
    image_paths = glob.glob(example_path)

    image_array_list = []
    character_list = []
    for image_path in image_paths:
        image_array_list.append( (np.mean(cv2.imread(image_path), axis=2)/255.).reshape(1,shape[0], shape[1]) )
        character_list.append( image_path.split('/')[-1].split('.')[0].replace('__',"\\") )


    return np.stack( image_array_list ), np.array(range(len(character_list))), np.array(character_list)



if __name__ == "__main__":

    batch_size = 32

    nb_epoch = 200
    data_augmentation = True

    # input image dimensions
    img_rows, img_cols = 28,28
    # the CIFAR10 images are RGB
    img_channels = 1

    # the data, shuffled and split between train and test sets
    #(X_train, y_train), (X_test, y_test) = cifar10.load_data()

    X_train, Y_train, labels = read_example_images("char2png/output/*.png") 
    pickle.dump(labels, open("labels.pkl", "w") )


    X_test, Y_test, labels = read_example_images("char2png/output/*.png") 

    print(labels)
    nb_classes = len(Y_train)
    print("Classes found: {}".format(nb_classes))


    #X_train, Y_train = read_example_images()

    print('X_train shape:', X_train.shape)
    print(X_train.shape[0], 'train samples')
    print(X_test.shape[0], 'test samples')

    # convert class vectors to binary class matrices
    Y_train = np_utils.to_categorical(Y_train, nb_classes)
    Y_test = np_utils.to_categorical(Y_test, nb_classes)

    model = Sequential()

    model.add(Convolution2D(32, 3, 3, border_mode='same',
                            input_shape=(img_channels, img_rows, img_cols)))
    model.add(Activation('relu'))
    model.add(Convolution2D(32, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Convolution2D(64, 3, 3, border_mode='same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(64, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nb_classes))
    model.add(Activation('softmax'))


    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    model.compile(loss='categorical_crossentropy',
                  optimizer=sgd,
                  metrics=['accuracy'])


    if not data_augmentation:
        print('Not using data augmentation.')
        model.fit(X_train, Y_train,
                  batch_size=batch_size,
                  nb_epoch=nb_epoch,
                  shuffle=True)
    else:
        print('Using real-time data augmentation.')

        # this will do preprocessing and realtime data augmentation
        datagen = ImageDataGenerator(
            featurewise_center=False,  # set input mean to 0 over the dataset
            samplewise_center=False,  # set each sample mean to 0
            featurewise_std_normalization=False,  # divide inputs by std of the dataset
            samplewise_std_normalization=False,  # divide each input by its std
            zca_whitening=False,  
            zoom_range=0.2, # apply ZCA whitening
            rotation_range=0.2,  # randomly rotate images in the range (degrees, 0 to 180)
            width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
            height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
            horizontal_flip=False,  # randomly flip images
            vertical_flip=False)  # randomly flip images

        # compute quantities required for featurewise normalization
        # (std, mean, and principal components if ZCA whitening is applied)
        datagen.fit(X_train)

        # fit the model on the batches generated by datagen.flow()
        hist = model.fit_generator(datagen.flow(X_train, Y_train,
                            batch_size=batch_size),
                            samples_per_epoch=X_train.shape[0],
                            nb_epoch=nb_epoch,
                            validation_data=(X_test, Y_test))


        print(hist.history)


        print("Saving model architecture...")
        json_string = model.to_json()
        open('model_architecture.json', 'w').write(json_string)

        print("Saving weights...")
        model.save_weights('model_weights.h5', overwrite=True)

        print("Finished.")


        

